{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/colt/github/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/colt/github/Mask_RCNN\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "#if not os.path.exists(COCO_MODEL_PATH):\n",
    "#    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readcv2(path_to_file):\n",
    "    x = cv2.imread(path_to_file)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    return x\n",
    "\n",
    "def remove_tag(image):\n",
    "    image[750:,700:,:] = 0\n",
    "    return image\n",
    "\n",
    "def count_pixels(colors,flat_image):\n",
    "    \"\"\"\n",
    "    count the number of times a given RGB appears in a flattened image.\n",
    "    \"\"\"\n",
    "    find_masks = dict()\n",
    "    for color in colors:\n",
    "        #print(color)\n",
    "        color_count = 0\n",
    "        for pixel in flat_image:\n",
    "            if sum(pixel == color) == 3: # this checks if the pixel value is equal to color in loop\n",
    "                color_count += 1\n",
    "        print(str(color) + ' pixel count -> ' + str(color_count))\n",
    "        find_masks[str(color)] = color_count\n",
    "    return(find_masks)\n",
    "# unique [r g b] -> COUNT of pixels with rgb in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from synvis import mask_mask\n",
    "def make_mask(directory,filename,verbose=0):\n",
    "    img_rgb = readcv2(directory + '/rgb/' + filename)\n",
    "    img_mask = readcv2(directory + '/mask/' + filename)\n",
    "    img_mask = remove_tag(img_mask)\n",
    "    \n",
    "    \n",
    "    X = img_mask.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42).fit(X)\n",
    "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    segmented_img = segmented_img.reshape(img_rgb.shape)\n",
    "    segmented_img = segmented_img.astype(\"uint8\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    img=segmented_img\n",
    "    \n",
    "    #todo make this smarter - assumptions are fine for now\n",
    "    mask_sizes = []\n",
    "    leaf_count = 0\n",
    "    #figure out how many leaves are present by getting # of pixels per kmeans cluster\n",
    "    for i in np.arange(len(kmeans.cluster_centers_)):\n",
    "        if i == 0: #this ignores the background cluster(!ASSUMPTION that it is largest.)\n",
    "            mask_sizes.append(1000) #large value to test that the first mask isn't TINY\n",
    "        else:\n",
    "            number_of_pixels = sum(kmeans.labels_ == i)\n",
    "            if ((number_of_pixels/mask_sizes[leaf_count-1])<.05): #assumption; this is good value\n",
    "                None\n",
    "            else:\n",
    "                mask_sizes.append(number_of_pixels)\n",
    "                leaf_count +=1\n",
    "    \n",
    "\n",
    "                \n",
    "\n",
    "    np_mask = np.zeros((img.shape[0],img.shape[1],leaf_count))\n",
    "                       \n",
    "    class_ids = []\n",
    "    for i in np.arange(leaf_count+1):\n",
    "        if i == 0: # ignore first mask ASSUMPTION is background\n",
    "            None\n",
    "        else:\n",
    "            class_ids.append(1)\n",
    "            np_mask[:,:,i-1] = (kmeans.labels_ == i).reshape((img.shape[0],img.shape[1]))\n",
    "          \n",
    "    if verbose == 1:\n",
    "        print('*visible* leaf count ' + str(leaf_count))\n",
    "        print('Synthetic Image')\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.show()\n",
    "        print(\"Instance Mask\")\n",
    "        plt.imshow(img_mask)\n",
    "        plt.show()\n",
    "        print('Kmeans Clustering ; k = 10')\n",
    "        plt.imshow(segmented_img)\n",
    "        plt.show()\n",
    "        print('Processed Instance Mask ; Second Leaf mask')\n",
    "        plt.imshow(np_mask[:,:,1])\n",
    "        plt.show()\n",
    "        print('Class IDs ' + str(class_ids))\n",
    "    \n",
    "    return np_mask,class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  1024\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               1\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SyntheticConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "    BATCH_SIZE = 1\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    #IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 1\n",
    "    \n",
    "    \n",
    "config = SyntheticConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_syn(self, dataset_dir):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"plant\", 1, \"leaf\")\n",
    "\n",
    "        \n",
    "        rgb_dir = dataset_dir + '/rgb/'\n",
    "        mask_dir = dataset_dir + '/mask/'\n",
    "        \n",
    "        \n",
    "        image_ids = []\n",
    "        for file in os.listdir(rgb_dir):\n",
    "            if 'png' in file:\n",
    "                image_ids.append(file)\n",
    "        \n",
    "        img_id = 0\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "            \"plantleaf\",\n",
    "            filename = image_id,\n",
    "            image_id = img_id,\n",
    "            path = dataset_dir + '/rgb/' + image_id,\n",
    "            )\n",
    "            img_id+=1\n",
    "        print('Loaded ' + str(img_id) + ' images')\n",
    "            \n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        directory = info['path'].split('/')[:4]\n",
    "        directory = \"/\".join(directory)\n",
    "        directory += '/'\n",
    "        #print(directory, info['filename'])\n",
    "        print('before')\n",
    "        mask,class_ids = make_mask(directory, info['filename'], verbose=1)\n",
    "        print('after')\n",
    "        #print('Loaded... something')\n",
    "        #print(mask)\n",
    "        #print(class_ids)\n",
    "        print('loaded mask')\n",
    "        return mask, np.array(class_ids)\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 images\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "2\n",
      "[{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'plant', 'id': 1, 'name': 'leaf'}]\n",
      "  0. BG                                                \n",
      "  1. leaf                                              \n"
     ]
    }
   ],
   "source": [
    "dataset = ShapesDataset()\n",
    "dataset.load_syn('/home/colt/tobak/')\n",
    "dataset.prepare()\n",
    "print(dataset.image_ids)\n",
    "print(dataset.num_classes)\n",
    "print(dataset.class_info)\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 images\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"Train the model.\"\"\"\n",
    "# Training dataset.\n",
    "dataset_dir = '/home/colt/tobak/'\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_syn(dataset_dir)\n",
    "dataset_train.prepare()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "*visible* leaf count 6\n",
      "Synthetic Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans Clustering ; k = 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Instance Mask ; Second Leaf mask\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IDs [1, 1, 1, 1, 1, 1]\n",
      "after\n",
      "loaded mask\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]]), array([1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.load_mask(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train network heads\n"
     ]
    }
   ],
   "source": [
    "print(\"Train network heads\")\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/colt/github/Mask_RCNN/shapes20201115T2305/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "Epoch 1/20\n",
      "before\n",
      "before\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-0820cbbc5c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             layers='heads')\n\u001b[0m",
      "\u001b[0;32m~/github/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_train,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_MODEL_PATH = '/home/colt/github/Mask_RCNN/mask_rcnn_coco.h5'\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/colt/logs/shapes20201115T2311/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "before\n",
      "Epoch 1/4\n",
      "before\n",
      "before\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-60d3c6a7a681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             layers='heads')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mend_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mminutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_train = time.time()\n",
    "model.train(dataset_train, dataset_train, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=4, \n",
    "            layers='heads')\n",
    "end_train = time.time()\n",
    "minutes = round((end_train - start_train) / 60, 2)\n",
    "print(f'Training took {minutes} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset.load_image(0)\n",
    "mask, class_ids = dataset.load_mask(0)\n",
    "visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "        dataset, config, image_id, use_mini_mask=False)\n",
    "log(\"molded_image\", image)\n",
    "log(\"mask\", mask)\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names,\n",
    "                            show_bbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Train the model.\"\"\"\n",
    "# Training dataset.\n",
    "dataset_dir = '/home/colt/tobak/'\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_syn(dataset_dir)\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Train network heads\")\n",
    "model.train(dataset_train, dataset_train,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/colt/github/Mask_RCNN/shapes20201115T2218/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/colt/tobak/ tobak.5.exr.png\n",
      "/home/colt/tobak/ tobak.31.exr.png\n",
      "/home/colt/tobak/ tobak.7.exr.png\n",
      "/home/colt/tobak/ tobak.40.exr.png\n",
      "/home/colt/tobak/ tobak.12.exr.png\n",
      "/home/colt/tobak/ tobak.35.exr.png\n",
      "/home/colt/tobak/ tobak.9.exr.png\n",
      "Epoch 1/20\n",
      "/home/colt/tobak/ tobak.22.exr.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-da489ed7338c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             layers='heads')\n\u001b[0m",
      "\u001b[0;32m~/github/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Train network heads\")\n",
    "model.train(dataset_train, dataset_train,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "def train(model, dataset_dir, subset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = NucleusDataset()\n",
    "    dataset_train.load_nucleus(dataset_dir, subset)\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = NucleusDataset()\n",
    "    dataset_val.load_nucleus(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # Image augmentation\n",
    "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.Multiply((0.8, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
    "    ])\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "    # If starting from imagenet, train heads only for a bit\n",
    "    # since they have random weights\n",
    "    print(\"Train network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=20,\n",
    "                augmentation=augmentation,\n",
    "                layers='heads')\n",
    "\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/colt/github/Mask_RCNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1768: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/colt/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/colt/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/colt/github/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/github/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/colt/github/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(6, 12)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn",
   "language": "python",
   "name": "maskrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
